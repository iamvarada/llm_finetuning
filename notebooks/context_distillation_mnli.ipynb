{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyNOJmgIq3lC54nyrL5qCmWK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"523082567a474eecbdb425667b4864ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_022fd2e5c1f442cab3fcabe7f705aa98","IPY_MODEL_699a43f177c84b6485a83b502e676f74","IPY_MODEL_e2d922aceedf42e8aab5f368c12aba74"],"layout":"IPY_MODEL_0be1e613d82246279adf50a97fa1e7b8"}},"022fd2e5c1f442cab3fcabe7f705aa98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_958b5851800e408c858ae5f41776139e","placeholder":"​","style":"IPY_MODEL_7bad1e4d0aa849118b28bd8e09d2ba73","value":"Map: 100%"}},"699a43f177c84b6485a83b502e676f74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9040c67f979481fa0042c88e32e73d1","max":6692,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d38ae3694a174fc0a0b8ac21f97cc320","value":6692}},"e2d922aceedf42e8aab5f368c12aba74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ada65e29f6548ef94cee145bd7d982f","placeholder":"​","style":"IPY_MODEL_c8757470fcfd45e8ae82d18f409b4db0","value":" 6692/6692 [00:00&lt;00:00, 10040.06 examples/s]"}},"0be1e613d82246279adf50a97fa1e7b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"958b5851800e408c858ae5f41776139e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bad1e4d0aa849118b28bd8e09d2ba73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9040c67f979481fa0042c88e32e73d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d38ae3694a174fc0a0b8ac21f97cc320":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ada65e29f6548ef94cee145bd7d982f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8757470fcfd45e8ae82d18f409b4db0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-6oE5hnVfkB","executionInfo":{"status":"ok","timestamp":1713624622309,"user_tz":420,"elapsed":27925,"user":{"displayName":"Gumpena Prasanth","userId":"05477373622431910909"}},"outputId":"b59bc581-62a5-4301-bf8a-f1d2fe5c73bc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weZOPDg7hid7","executionInfo":{"status":"ok","timestamp":1713624813699,"user_tz":420,"elapsed":166,"user":{"displayName":"Gumpena Prasanth","userId":"05477373622431910909"}},"outputId":"b317eaaf-f624-4cc4-9270-5b3f3f63acae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/DL_project/llm_finetuning/notebooks/"],"metadata":{"id":"vfn0qJLsg4wx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713624815391,"user_tz":420,"elapsed":405,"user":{"displayName":"Gumpena Prasanth","userId":"05477373622431910909"}},"outputId":"b9d147d1-f27c-475f-d42a-6f833c1e2768"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL_project/llm_finetuning/notebooks\n"]}]},{"cell_type":"code","source":["!pip install -q transformers accelerate bitsandbytes datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAhrMw3EmElS","executionInfo":{"status":"ok","timestamp":1713624883271,"user_tz":420,"elapsed":66726,"user":{"displayName":"Gumpena Prasanth","userId":"05477373622431910909"}},"outputId":"e119077a-5d36-4306-edd1-0896fc66da26"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from torch.nn.functional import kl_div, softmax, log_softmax\n","from torch.optim import AdamW\n","from datasets import load_dataset, ClassLabel\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import DataLoader\n","from torch.nn import CrossEntropyLoss\n","from tqdm import tqdm\n","\n","\n","torch.cuda.empty_cache()\n","\n","# for reproducibility\n","np.random.seed(42)\n","\n","torch.manual_seed(42)\n","\n","if torch.cuda.is_available():\n","  torch.cuda.manual_seed_all(42)\n","\n","\n","data = load_dataset(\"glue\", \"mnli\")\n","hans_data = load_dataset(\"hans\")\n","#print(hans_data.keys())\n","\n","#Below method is refenced from: https://github.com/uds-lsv/llmft/blob/main/notebooks/majority_baseline.ipynb\n","def binarize_mnli(dataset, remove_neutral=True):\n","    if remove_neutral:\n","        # neutral class has label 1\n","        dataset = dataset.filter(lambda example: example[\"label\"] != 1)\n","\n","    # change labels of contradiction examples from 2 to 1\n","    def change_label(example):\n","        # convert labels 2 into labels 1. this merges the neutral and contradiction class\n","        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n","        return example\n","\n","    # change labels\n","    dataset = dataset.map(change_label)\n","\n","    # change features to reflect the new labels\n","    features = dataset[\"train\"].features.copy()\n","    features[\"label\"] = ClassLabel(num_classes=2, names=['entailment', 'contradiction'], id=None)\n","    dataset = dataset.cast(features)  # overwrite old features\n","\n","    return dataset\n","\n","data = binarize_mnli(data, remove_neutral=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the original model\n","original_model = AutoModelForSequenceClassification.from_pretrained(\"facebook/opt-125m\")\n","original_model.to(device)  # Move the model to the device (gpu if available)\n","\n","# Load the student model\n","model = AutoModelForSequenceClassification.from_pretrained(\"facebook/opt-125m\")\n","model.to(device)  # Move the model to the device (gpu if available)\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n","\n","# Define the fixed context\n","fixed_context = \"Given the premise, does the hypothesis hold true? \"\n","\n","##Prepare the inputs with the fixed context\n","def manipulate_inputs(batch):\n","    encoding = tokenizer([f'{fixed_context} Premise: {premise} Hypothesis: {hypothesis}'\n","                          for premise, hypothesis in zip(batch[\"premise\"], batch[\"hypothesis\"])],\n","                          truncation=True, padding=\"max_length\", max_length=128, return_tensors='pt')\n","    batch[\"input_ids\"] = encoding[\"input_ids\"].squeeze()\n","    batch[\"attention_mask\"] = encoding[\"attention_mask\"].squeeze()\n","    return batch\n","\n","data = data.map(manipulate_inputs, batched=True)\n","hans_data = hans_data.map(manipulate_inputs, batched=True)\n","\n","# print(\"************\")\n","# print((data[\"train\"][0]))\n","\n","# Define a custom loss function\n","def custom_loss(model_probs, original_model_probs):\n","    return kl_div(model_probs.log_softmax(dim=-1), original_model_probs, reduction='batchmean')\n","\n","# Define the optimizer\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","\n","#training and eval datasets\n","train_dataset = data[\"train\"]\n","in_domain_eval_dataset = data[\"validation_matched\"]\n","out_of_domain_eval_dataset = hans_data[\"validation\"]\n","\n","\n","\n","# print(len(train_dataset))\n","\n","from torch.nn.utils.rnn import pad_sequence\n","\n","def collate_fn(batch):\n","    premises = [item['premise'] for item in batch]\n","    hypotheses = [item['hypothesis'] for item in batch]\n","    labels = torch.tensor([item['label'] for item in batch])\n","    input_ids = pad_sequence([torch.tensor(item['input_ids']) for item in batch], batch_first=True)\n","    attention_mask = pad_sequence([torch.tensor(item['attention_mask']) for item in batch], batch_first=True)\n","\n","    return {'premise': premises, 'hypothesis': hypotheses, 'label': labels, 'input_ids': input_ids, 'attention_mask': attention_mask}\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\n","# Define the dataloaders for evaluation\n","in_domain_dataloader = DataLoader(in_domain_eval_dataset, batch_size=32, collate_fn=collate_fn)\n","out_of_domain_dataloader = DataLoader(out_of_domain_eval_dataset, batch_size=32, collate_fn=collate_fn)\n","\n","\n","# print(type(train_dataloader))\n","# # Convert the DataLoader to an iterator\n","# train_iter = iter(train_dataloader)\n","\n","# # Get the first element\n","# first_element = next(train_iter)\n","\n","# # Print the first element\n","# print(first_element)\n","\n","# print(\"**************************\")\n","# exit(1)\n","\n","\n","# Define the original task loss function\n","task_loss = CrossEntropyLoss()\n","\n","# Initialize the lists to store the accuracies\n","in_domain_accuracies = []\n","out_of_domain_accuracies = []\n","\n","# Custom training loop\n","\n","for epoch in range(3):  # num_train_epochs\n","  model.train()\n","  batch_count = 0\n","  for batch in tqdm(train_dataloader, desc=\"Training\"):\n","    #print(\"training batch num: \", batch_count, \"of epoch: \", epoch)\n","    # Move the batch tensors to the same device as the model\n","    #print(batch[\"input_ids\"].shape, batch[\"label\"].shape)\n","    # print(\"hhhhhhhhhhhhhhhhhh\")\n","    # print(len(batch[\"premise\"]))\n","    # print(len(batch[\"input_ids\"]))\n","    # print(len(batch[\"label\"]))\n","    input_ids = batch[\"input_ids\"].to(device)\n","    attention_mask = batch[\"attention_mask\"].to(device)\n","    labels = batch[\"label\"].to(device)\n","\n","    # Forward pass through the original model\n","    with torch.no_grad():\n","      outputs_original = original_model(input_ids=input_ids, attention_mask=attention_mask)\n","      original_model_probs = outputs_original.logits\n","\n","    # Forward pass through the student model\n","    outputs_student = model(input_ids=input_ids, attention_mask=attention_mask)\n","    model_probs = outputs_student.logits\n","\n","    # Compute the KL divergence loss\n","    distillation_loss = custom_loss(model_probs, original_model_probs)\n","\n","\n","    # Compute the task loss\n","    classification_loss = task_loss(outputs_student.logits, labels)\n","\n","    # Combine the losses\n","    loss = 0.5 * distillation_loss + 0.5 * classification_loss\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","    batch_count = batch_count + 1\n","\n","  # Evaluation loop for in-domain accuracy\n","  model.eval()\n","  correct_predictions = 0\n","  total_predictions = 0\n","\n","  in_domain_batch_count = 0\n","  with torch.no_grad():\n","    for batch in tqdm(in_domain_dataloader, desc=\"Evaluating in-domain\"):\n","      #print(\"eval in-domain batch num: \", in_domain_batch_count, \"of epoch: \", epoch)\n","      # Move batch to device\n","      input_ids = batch[\"input_ids\"].to(device)\n","      attention_mask = batch[\"attention_mask\"].to(device)\n","      labels = batch[\"label\"].to(device)\n","\n","      # Forward pass through the fine-tuned model\n","      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","      predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","      # Update counters\n","      correct_predictions += (predictions == labels).sum().item()\n","      total_predictions += len(labels)\n","      in_domain_batch_count = in_domain_batch_count + 1\n","\n","  in_domain_accuracy = correct_predictions / total_predictions\n","  print(f\"In-domain accuracy: {in_domain_accuracy}\")\n","\n","  # Evaluation loop for out-of-domain accuracy\n","  correct_predictions = 0\n","  total_predictions = 0\n","\n","  out_of_domain_batch_count = 0\n","  with torch.no_grad():\n","    for batch in tqdm(out_of_domain_dataloader, desc=\"Evaluating out-domain\"):\n","      #print(\"eval out-of-domain batch num: \", out_of_domain_batch_count, \"of epoch: \", epoch)\n","      # Move batch to device\n","      input_ids = batch[\"input_ids\"].to(device)\n","      attention_mask = batch[\"attention_mask\"].to(device)\n","      labels = batch[\"label\"].to(device)\n","\n","      # Forward pass through the fine-tuned model\n","      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","      predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","      # Update counters\n","      correct_predictions += (predictions == labels).sum().item()\n","      total_predictions += len(labels)\n","      out_of_domain_batch_count = out_of_domain_batch_count + 1\n","\n","  out_of_domain_accuracy = correct_predictions / total_predictions\n","  print(f\"Out-of-domain accuracy: {out_of_domain_accuracy}\")\n","\n","  # Add the accuracies to the lists\n","  in_domain_accuracies.append(in_domain_accuracy)\n","  out_of_domain_accuracies.append(out_of_domain_accuracy)\n","\n","# Compute the maximum and average accuracies\n","max_in_domain_accuracy = max(in_domain_accuracies)\n","average_in_domain_accuracy = sum(in_domain_accuracies) / len(in_domain_accuracies)\n","\n","max_out_of_domain_accuracy = max(out_of_domain_accuracies)\n","average_out_of_domain_accuracy = sum(out_of_domain_accuracies) / len(out_of_domain_accuracies)\n","\n","# Print the maximum and average accuracies\n","print(f\"Maximum in-domain accuracy: {max_in_domain_accuracy}\")\n","print(f\"Average in-domain accuracy: {average_in_domain_accuracy}\")\n","print(f\"Maximum out-of-domain accuracy: {max_out_of_domain_accuracy}\")\n","print(f\"Average out-of-domain accuracy: {average_out_of_domain_accuracy}\")\n","\n","# # Save the accuracies to a CSV file\n","# results_df = pd.DataFrame({\n","#     \"in_domain_accuracy\": in_domain_accuracies,\n","#     \"out_of_domain_accuracy\": out_of_domain_accuracies\n","# })\n","# results_df.to_csv(\"../Results/context_distillation_mnli.csv\", index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":662,"referenced_widgets":["523082567a474eecbdb425667b4864ce","022fd2e5c1f442cab3fcabe7f705aa98","699a43f177c84b6485a83b502e676f74","e2d922aceedf42e8aab5f368c12aba74","0be1e613d82246279adf50a97fa1e7b8","958b5851800e408c858ae5f41776139e","7bad1e4d0aa849118b28bd8e09d2ba73","f9040c67f979481fa0042c88e32e73d1","d38ae3694a174fc0a0b8ac21f97cc320","9ada65e29f6548ef94cee145bd7d982f","c8757470fcfd45e8ae82d18f409b4db0"]},"id":"nEfGotLUr4cc","executionInfo":{"status":"error","timestamp":1713646103973,"user_tz":420,"elapsed":20869737,"user":{"displayName":"Gumpena Prasanth","userId":"05477373622431910909"}},"outputId":"8fbffb90-db67-427e-e468-7fa9bed313f8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-125m and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-125m and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6692 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"523082567a474eecbdb425667b4864ce"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 8182/8182 [1:52:04<00:00,  1.22it/s]\n","Evaluating in-domain: 100%|██████████| 210/210 [00:42<00:00,  4.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["In-domain accuracy: 0.6313508667065152\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating out-domain: 100%|██████████| 938/938 [03:09<00:00,  4.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Out-of-domain accuracy: 0.5003666666666666\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 8182/8182 [1:52:05<00:00,  1.22it/s]\n","Evaluating in-domain: 100%|██████████| 210/210 [00:42<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["In-domain accuracy: 0.6676628810520024\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating out-domain: 100%|██████████| 938/938 [03:08<00:00,  4.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Out-of-domain accuracy: 0.5249666666666667\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 8182/8182 [1:51:59<00:00,  1.22it/s]\n","Evaluating in-domain: 100%|██████████| 210/210 [00:42<00:00,  4.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["In-domain accuracy: 0.7208607292289301\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating out-domain: 100%|██████████| 938/938 [03:08<00:00,  4.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Out-of-domain accuracy: 0.49746666666666667\n","Maximum in-domain accuracy: 0.7208607292289301\n","Average in-domain accuracy: 0.6732914923291493\n","Maximum out-of-domain accuracy: 0.5249666666666667\n","Average out-of-domain accuracy: 0.5075999999999999\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-6472c814cb7a>\u001b[0m in \u001b[0;36m<cell line: 248>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;31m# Save the accuracies to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m results_df = pd.DataFrame({\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;34m\"in_domain_accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0min_domain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;34m\"out_of_domain_accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout_of_domain_accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","source":["import pandas as pd\n","# Save the accuracies to a CSV file\n","results_df = pd.DataFrame({\n","    \"in_domain_accuracy\": in_domain_accuracies,\n","    \"out_of_domain_accuracy\": out_of_domain_accuracies\n","})\n","results_df.to_csv(\"../Results/context_distillation_mnli.csv\", index=False)\n"],"metadata":{"id":"sWP-Gl0jWuUe","executionInfo":{"status":"ok","timestamp":1713647591019,"user_tz":420,"elapsed":202,"user":{"displayName":"Gumpena Prasanth","userId":"05477373622431910909"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OSTzFYB2r5aC"},"execution_count":null,"outputs":[]}]}